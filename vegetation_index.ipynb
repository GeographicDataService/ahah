{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b811489",
   "metadata": {},
   "source": [
    "# Setup and Monitoring\n",
    "\n",
    "The following code generates the ambient Greenspace indicator.\n",
    "\n",
    "### Google Cloud Setup\n",
    "\n",
    "There are a few steps to set up Google Cloud for use with Earth Engine and Cloud Storage.\n",
    "\n",
    "1. **Install Google Cloud SDK**\n",
    "For example - on macOS with MacPorts\n",
    "\n",
    "```sudo port install google-cloud-sdk```\n",
    "\n",
    "2. **Authenticate with Google Cloud**\n",
    "The following command needs to be run in a terminal and will open a browser window for authentication\n",
    "\n",
    "```bashgcloud auth login```\n",
    "\n",
    "3. **Create a Google Cloud Project**\n",
    "\n",
    "Go to [console.cloud.google.com](https://console.cloud.google.com/)\n",
    "Create a new project or select an existing one\n",
    "Note your project ID\n",
    "\n",
    "4. **Enable Required APIs**\n",
    "\n",
    "Enable the Earth Engine API in the project\n",
    "Enable the Cloud Storage API in the project\n",
    "\n",
    "5. **Register for Earth Engine**\n",
    "\n",
    "Visit code.earthengine.google.com and register your Google account\n",
    "\n",
    "6. **Create a Cloud Storage Bucket**\n",
    "\n",
    "In Cloud Console, go to Cloud Storage and \"Create bucket\"\n",
    "The following code expects a bucket named 'a-h-a-h'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # For handling file paths in a cross-platform way\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import geopandas as gpd  # For geospatial data handling\n",
    "import requests  # For making HTTP requests\n",
    "from bs4 import BeautifulSoup  # For parsing HTML content\n",
    "import re  # For regular expressions\n",
    "import requests  # Duplicate import (consider removing)\n",
    "import time  # For time-related functions\n",
    "from typing import Optional  # For type hints\n",
    "import io  # For in-memory I/O operations\n",
    "import os  # For operating system interfaces\n",
    "import tempfile  # For temporary file creation\n",
    "import zipfile  # For ZIP file handling\n",
    "import urllib.request  # For URL retrieval\n",
    "import ee  # For Google Earth Engine API\n",
    "import subprocess  # For running subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b314a",
   "metadata": {},
   "source": [
    "## Task Monitoring / Cancelation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor task progress\n",
    "result = subprocess.run(['earthengine', 'task', 'list'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3382d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print task list until a specific task ID is found\n",
    "result = subprocess.run(['earthengine', 'task', 'list'], capture_output=True, text=True)\n",
    "\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if '2Q4Y2CEVXZ5UAQWDZ4T6SIJ5' in line:\n",
    "        break\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43110ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel all running or ready tasks\n",
    "for task in ee.batch.Task.list():\n",
    "    if task.state in ['RUNNING', 'READY']:\n",
    "        task.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af44bd",
   "metadata": {},
   "source": [
    "# Create UK Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ad0a5",
   "metadata": {},
   "source": [
    "If the bounrdary shape files are not already in your Earth Engine assets, run the following code to create them.\n",
    "\n",
    "```python\n",
    "boundaries_all_UK = gpd.read_parquet(Path(\"data\") / \"boundary\" / \"LSOA_DZ_SDZ_21_22.parquet\")\n",
    "\n",
    "zip_url = \"https://www.nisra.gov.uk/files/nisra/publications/geography-sdz2021-esri-shapefile.zip\"\n",
    "\n",
    "# create a temporary directory and download the zip there\n",
    "tmp_dir = tempfile.mkdtemp()\n",
    "zip_path = os.path.join(tmp_dir, \"sdz2021.zip\")\n",
    "urllib.request.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "# Extract and import Northern Ireland SDZ 2021 shapefile\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(tmp_dir)\n",
    "\n",
    "# Read the shapefile\n",
    "NI_boundaries = gpd.read_file(os.path.join(tmp_dir, \"SDZ2021.shp\"))\n",
    "\n",
    "NI_boundaries = NI_boundaries.rename(columns={\"SDZ2021_cd\": \"LSOA_DZ_SDZ_21_22\"})\n",
    "NI_boundaries = NI_boundaries[[\"LSOA_DZ_SDZ_21_22\", \"geometry\"]].copy()\n",
    "\n",
    "NI_boundaries = NI_boundaries.to_crs(boundaries_all.crs)\n",
    "\n",
    "boundaries_all_UK = gpd.GeoDataFrame(\n",
    "    pd.concat([boundaries_all, NI_boundaries], ignore_index=True),\n",
    "    geometry=\"geometry\",\n",
    "    crs=boundaries_all.crs\n",
    ")\n",
    "\n",
    "# --- Reproject to WGS84 (required for GEE) ---\n",
    "boundaries_gee = boundaries_all_UK.to_crs('EPSG:4326')\n",
    "\n",
    "# Export to shapefile\n",
    "output_dir = Path('./data/raw_data/gee_upload')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "shp_path = output_dir / 'boundaries_uk.shp'\n",
    "boundaries_gee.to_file(shp_path, driver='ESRI Shapefile')\n",
    "\n",
    "print(f'Saved to {shp_path}')\n",
    "\n",
    "# Upload all shapefile components to GCS ---\n",
    "bucket = 'a-h-a-h'\n",
    "gcs_folder = 'gee_uploads'\n",
    "\n",
    "shp_extensions = ['.shp', '.shx', '.dbf', '.prj', '.cpg']\n",
    "\n",
    "for ext in shp_extensions:\n",
    "    local_file = shp_path.with_suffix(ext)\n",
    "    if local_file.exists():\n",
    "        gcs_path = f'gs://{bucket}/{gcs_folder}/{local_file.name}'\n",
    "        print(f'Uploading {local_file.name}...')\n",
    "        subprocess.run(['gsutil', 'cp', str(local_file), gcs_path], check=True)\n",
    "\n",
    "print('All files uploaded to GCS')\n",
    "\n",
    "# --- Step 4: Ingest into Earth Engine ---\n",
    "asset_id = 'projects/ndvi-inspire/assets/boundaries_uk'\n",
    "gcs_shp = f'gs://{bucket}/{gcs_folder}/boundaries_uk.shp'\n",
    "\n",
    "cmd = [\n",
    "    'earthengine',\n",
    "    'upload',\n",
    "    'table',\n",
    "    f'--asset_id={asset_id}',\n",
    "    gcs_shp\n",
    "]\n",
    "\n",
    "print(f'Running: {\" \".join(cmd)}')\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "print('stdout:', result.stdout)\n",
    "print('stderr:', result.stderr)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "379b4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43914 features; CRS: EPSG:27700\n"
     ]
    }
   ],
   "source": [
    "shp_path = Path('data/raw_data/gee_upload/boundaries_uk.shp')\n",
    "if not shp_path.exists():\n",
    "    raise FileNotFoundError(f\"Shapefile not found: {shp_path}\")\n",
    "\n",
    "boundaries_all_UK = gpd.read_file(shp_path)\n",
    "\n",
    "# Reproject to OSGB (EPSG:27700)\n",
    "boundaries_all_UK = boundaries_all_UK.to_crs(epsg=27700)\n",
    "\n",
    "print(f\"Loaded {len(boundaries_all_UK)} features; CRS: {boundaries_all_UK.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f66118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Earth Engine with a specific project\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='ndvi-inspire')\n",
    "\n",
    "# Set the project\n",
    "result = subprocess.run(['earthengine', 'set_project', 'ndvi-inspire'], capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca092e1e",
   "metadata": {},
   "source": [
    "# 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2437cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud masking for Sentinel-2\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using SCL band, but keep original for pixel counting\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    \n",
    "    total_pixels = ee.Image.constant(1).rename('total_pixels')\n",
    "    valid_pixels = ee.Image.constant(1).updateMask(mask).rename('valid_pixels')\n",
    "    \n",
    "    return image.updateMask(mask).addBands([total_pixels, valid_pixels])\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Calculate NDVI, EVI, and Fractional Vegetation Cover\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    nir = image.select('B8').divide(10000)\n",
    "    red = image.select('B4').divide(10000)\n",
    "    blue = image.select('B2').divide(10000)\n",
    "    \n",
    "    evi = nir.subtract(red).multiply(2.5).divide(\n",
    "        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n",
    "    ).rename('EVI')\n",
    "    \n",
    "    # Fractional Vegetation Cover\n",
    "    ndvi_soil = 0.2\n",
    "    ndvi_veg = 0.86\n",
    "    fvc = ndvi.subtract(ndvi_soil).divide(ndvi_veg - ndvi_soil).pow(2).clamp(0, 1).rename('FVC')\n",
    "    \n",
    "    return image.addBands([ndvi, evi, fvc])\n",
    "\n",
    "\n",
    "# Main processing\n",
    "start_date = '2025-04-01'\n",
    "end_date = '2025-10-31'\n",
    "\n",
    "s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "      .filterDate(start_date, end_date)\n",
    "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "      .map(mask_s2_clouds)\n",
    "      .map(add_indices))\n",
    "\n",
    "# Create composite\n",
    "composite = s2.select(['NDVI', 'EVI', 'FVC']).median()\n",
    "\n",
    "# Pixel counts - sum across collection\n",
    "pixel_counts = s2.select(['total_pixels', 'valid_pixels']).sum()\n",
    "\n",
    "# Build combined reducer for all stats\n",
    "reducer = (\n",
    "    ee.Reducer.mean()\n",
    "    .combine(ee.Reducer.median(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.stdDev(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.max(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.min(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.count(), sharedInputs=True)\n",
    ")\n",
    "\n",
    "# Load the boundaries\n",
    "boundaries = ee.FeatureCollection('projects/ndvi-inspire/assets/boundaries_uk')\n",
    "\n",
    "print(f'Loaded {boundaries.size().getInfo()} features')\n",
    "\n",
    "# Extract statistics\n",
    "veg_stats = composite.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=reducer,\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "pixel_stats = pixel_counts.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "# Export to your GCS bucket\n",
    "task1 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=veg_stats,\n",
    "    description='uk_veg_stats',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_veg_stats',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task2 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=pixel_stats,\n",
    "    description='uk_pixel_counts',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_pixel_counts',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task1.start()\n",
    "task2.start()\n",
    "\n",
    "print('Export tasks started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory for GEE exports if it doesn't exist\n",
    "output_dir = Path('data/raw_data/gee_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the vegetation statistics CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_veg_stats.csv', str(output_dir)], check=True)\n",
    "# Download the pixel counts CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_pixel_counts.csv', str(output_dir)], check=True)\n",
    "\n",
    "# Read the downloaded CSV files into pandas DataFrames\n",
    "veg_stats = pd.read_csv(output_dir / 'uk_veg_stats.csv')\n",
    "pixel_counts = pd.read_csv(output_dir / 'uk_pixel_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fff5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and merge\n",
    "veg_stats = veg_stats[['LSOA_DZ_SD', 'EVI_count', 'EVI_max', 'EVI_mean', 'EVI_median', 'EVI_min', 'EVI_stdDev', 'FVC_count', 'FVC_max', 'FVC_mean', 'FVC_median', 'FVC_min', 'FVC_stdDev', 'NDVI_count', 'NDVI_max', 'NDVI_mean', 'NDVI_median', 'NDVI_min', 'NDVI_stdDev']]\n",
    "pixel_counts = pixel_counts.drop(columns=['system:index', '.geo'])\n",
    "veg_stats = veg_stats.merge(pixel_counts, on='LSOA_DZ_SD', how='left')\n",
    "\n",
    "# Merge veg_stats into boundaries_all_UK by matching LSOA IDs\n",
    "boundaries_all_UK = boundaries_all_UK.merge(\n",
    "    veg_stats,\n",
    "    left_on=\"LSOA_DZ_SDZ_21_22\",\n",
    "    right_on=\"LSOA_DZ_SD\",\n",
    "    how=\"left\"\n",
    ").drop(columns=[\"LSOA_DZ_SD\"], errors=\"ignore\")\n",
    "\n",
    "out_dir = Path(\"data\") / \"raw_data\" / \"gee_exports\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / \"Vegetation_Indicies_2025.parquet\"\n",
    "boundaries_all_UK.to_parquet(out_path, index=False)\n",
    "print(\"Saved geoparquet to\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4575ed",
   "metadata": {},
   "source": [
    "# 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abca42a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43914 features\n",
      "Export tasks started\n"
     ]
    }
   ],
   "source": [
    "# Cloud masking for Sentinel-2\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using SCL band, but keep original for pixel counting\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    \n",
    "    total_pixels = ee.Image.constant(1).rename('total_pixels')\n",
    "    valid_pixels = ee.Image.constant(1).updateMask(mask).rename('valid_pixels')\n",
    "    \n",
    "    return image.updateMask(mask).addBands([total_pixels, valid_pixels])\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Calculate NDVI, EVI, and Fractional Vegetation Cover\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    nir = image.select('B8').divide(10000)\n",
    "    red = image.select('B4').divide(10000)\n",
    "    blue = image.select('B2').divide(10000)\n",
    "    \n",
    "    evi = nir.subtract(red).multiply(2.5).divide(\n",
    "        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n",
    "    ).rename('EVI')\n",
    "    \n",
    "    # Fractional Vegetation Cover\n",
    "    ndvi_soil = 0.2\n",
    "    ndvi_veg = 0.86\n",
    "    fvc = ndvi.subtract(ndvi_soil).divide(ndvi_veg - ndvi_soil).pow(2).clamp(0, 1).rename('FVC')\n",
    "    \n",
    "    return image.addBands([ndvi, evi, fvc])\n",
    "\n",
    "\n",
    "# Main processing\n",
    "start_date = '2024-04-01'\n",
    "end_date = '2024-10-31'\n",
    "\n",
    "s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "      .filterDate(start_date, end_date)\n",
    "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "      .map(mask_s2_clouds)\n",
    "      .map(add_indices))\n",
    "\n",
    "# Create composite\n",
    "composite = s2.select(['NDVI', 'EVI', 'FVC']).median()\n",
    "\n",
    "# Pixel counts - sum across collection\n",
    "pixel_counts = s2.select(['total_pixels', 'valid_pixels']).sum()\n",
    "\n",
    "# Build combined reducer for all stats\n",
    "reducer = (\n",
    "    ee.Reducer.mean()\n",
    "    .combine(ee.Reducer.median(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.stdDev(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.max(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.min(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.count(), sharedInputs=True)\n",
    ")\n",
    "\n",
    "# Load the boundaries\n",
    "boundaries = ee.FeatureCollection('projects/ndvi-inspire/assets/boundaries_uk')\n",
    "\n",
    "print(f'Loaded {boundaries.size().getInfo()} features')\n",
    "\n",
    "# Extract statistics\n",
    "veg_stats = composite.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=reducer,\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "pixel_stats = pixel_counts.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "# Export to your GCS bucket\n",
    "task1 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=veg_stats,\n",
    "    description='uk_veg_stats_2024',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_veg_stats_2024',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task2 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=pixel_stats,\n",
    "    description='uk_pixel_counts_2024',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_pixel_counts_2024',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task1.start()\n",
    "task2.start()\n",
    "\n",
    "print('Export tasks started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a021273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://a-h-a-h/gee_exports/uk_veg_stats_2024.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "| [1 files][283.0 MiB/283.0 MiB]                                                \n",
      "Operation completed over 1 objects/283.0 MiB.                                    \n",
      "Copying gs://a-h-a-h/gee_exports/uk_pixel_counts_2024.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "/ [1 files][272.1 MiB/272.1 MiB]                                                \n",
      "Operation completed over 1 objects/272.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Create the output directory for GEE exports if it doesn't exist\n",
    "output_dir = Path('data/raw_data/gee_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the vegetation statistics CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_veg_stats_2024.csv', str(output_dir)], check=True)\n",
    "# Download the pixel counts CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_pixel_counts_2024.csv', str(output_dir)], check=True)\n",
    "\n",
    "# Read the downloaded CSV files into pandas DataFrames\n",
    "veg_stats = pd.read_csv(output_dir / 'uk_veg_stats_2024.csv')\n",
    "pixel_counts = pd.read_csv(output_dir / 'uk_pixel_counts_2024.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92b7f7",
   "metadata": {},
   "source": [
    "## 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "618273d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43914 features\n",
      "Export tasks started\n"
     ]
    }
   ],
   "source": [
    "# Cloud masking for Sentinel-2\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using SCL band, but keep original for pixel counting\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    \n",
    "    total_pixels = ee.Image.constant(1).rename('total_pixels')\n",
    "    valid_pixels = ee.Image.constant(1).updateMask(mask).rename('valid_pixels')\n",
    "    \n",
    "    return image.updateMask(mask).addBands([total_pixels, valid_pixels])\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Calculate NDVI, EVI, and Fractional Vegetation Cover\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    nir = image.select('B8').divide(10000)\n",
    "    red = image.select('B4').divide(10000)\n",
    "    blue = image.select('B2').divide(10000)\n",
    "    \n",
    "    evi = nir.subtract(red).multiply(2.5).divide(\n",
    "        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n",
    "    ).rename('EVI')\n",
    "    \n",
    "    # Fractional Vegetation Cover\n",
    "    ndvi_soil = 0.2\n",
    "    ndvi_veg = 0.86\n",
    "    fvc = ndvi.subtract(ndvi_soil).divide(ndvi_veg - ndvi_soil).pow(2).clamp(0, 1).rename('FVC')\n",
    "    \n",
    "    return image.addBands([ndvi, evi, fvc])\n",
    "\n",
    "\n",
    "# Main processing\n",
    "start_date = '2023-04-01'\n",
    "end_date = '2023-10-31'\n",
    "\n",
    "s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "      .filterDate(start_date, end_date)\n",
    "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "      .map(mask_s2_clouds)\n",
    "      .map(add_indices))\n",
    "\n",
    "# Create composite\n",
    "composite = s2.select(['NDVI', 'EVI', 'FVC']).median()\n",
    "\n",
    "# Pixel counts - sum across collection\n",
    "pixel_counts = s2.select(['total_pixels', 'valid_pixels']).sum()\n",
    "\n",
    "# Build combined reducer for all stats\n",
    "reducer = (\n",
    "    ee.Reducer.mean()\n",
    "    .combine(ee.Reducer.median(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.stdDev(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.max(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.min(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.count(), sharedInputs=True)\n",
    ")\n",
    "\n",
    "# Load the boundaries\n",
    "boundaries = ee.FeatureCollection('projects/ndvi-inspire/assets/boundaries_uk')\n",
    "\n",
    "print(f'Loaded {boundaries.size().getInfo()} features')\n",
    "\n",
    "# Extract statistics\n",
    "veg_stats = composite.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=reducer,\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "pixel_stats = pixel_counts.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "# Export to your GCS bucket\n",
    "task1 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=veg_stats,\n",
    "    description='uk_veg_stats_2023',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_veg_stats_2023',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task2 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=pixel_stats,\n",
    "    description='uk_pixel_counts_2023',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_pixel_counts_2023',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task1.start()\n",
    "task2.start()\n",
    "\n",
    "print('Export tasks started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ec17cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://a-h-a-h/gee_exports/uk_veg_stats_2023.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "/ [1 files][283.0 MiB/283.0 MiB]                                                \n",
      "Operation completed over 1 objects/283.0 MiB.                                    \n",
      "Copying gs://a-h-a-h/gee_exports/uk_pixel_counts_2023.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "\\ [1 files][272.1 MiB/272.1 MiB]                                                \n",
      "Operation completed over 1 objects/272.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Create the output directory for GEE exports if it doesn't exist\n",
    "output_dir = Path('data/raw_data/gee_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the vegetation statistics CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_veg_stats_2023.csv', str(output_dir)], check=True)\n",
    "# Download the pixel counts CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_pixel_counts_2023.csv', str(output_dir)], check=True)\n",
    "\n",
    "# Read the downloaded CSV files into pandas DataFrames\n",
    "veg_stats = pd.read_csv(output_dir / 'uk_veg_stats_2023.csv')\n",
    "pixel_counts = pd.read_csv(output_dir / 'uk_pixel_counts_2023.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038aeae",
   "metadata": {},
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94e51a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43914 features\n",
      "Export tasks started\n"
     ]
    }
   ],
   "source": [
    "# Cloud masking for Sentinel-2\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using SCL band, but keep original for pixel counting\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    \n",
    "    total_pixels = ee.Image.constant(1).rename('total_pixels')\n",
    "    valid_pixels = ee.Image.constant(1).updateMask(mask).rename('valid_pixels')\n",
    "    \n",
    "    return image.updateMask(mask).addBands([total_pixels, valid_pixels])\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Calculate NDVI, EVI, and Fractional Vegetation Cover\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    nir = image.select('B8').divide(10000)\n",
    "    red = image.select('B4').divide(10000)\n",
    "    blue = image.select('B2').divide(10000)\n",
    "    \n",
    "    evi = nir.subtract(red).multiply(2.5).divide(\n",
    "        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n",
    "    ).rename('EVI')\n",
    "    \n",
    "    # Fractional Vegetation Cover\n",
    "    ndvi_soil = 0.2\n",
    "    ndvi_veg = 0.86\n",
    "    fvc = ndvi.subtract(ndvi_soil).divide(ndvi_veg - ndvi_soil).pow(2).clamp(0, 1).rename('FVC')\n",
    "    \n",
    "    return image.addBands([ndvi, evi, fvc])\n",
    "\n",
    "\n",
    "# Main processing\n",
    "start_date = '2022-04-01'\n",
    "end_date = '2022-10-31'\n",
    "\n",
    "s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "      .filterDate(start_date, end_date)\n",
    "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "      .map(mask_s2_clouds)\n",
    "      .map(add_indices))\n",
    "\n",
    "# Create composite\n",
    "composite = s2.select(['NDVI', 'EVI', 'FVC']).median()\n",
    "\n",
    "# Pixel counts - sum across collection\n",
    "pixel_counts = s2.select(['total_pixels', 'valid_pixels']).sum()\n",
    "\n",
    "# Build combined reducer for all stats\n",
    "reducer = (\n",
    "    ee.Reducer.mean()\n",
    "    .combine(ee.Reducer.median(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.stdDev(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.max(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.min(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.count(), sharedInputs=True)\n",
    ")\n",
    "\n",
    "# Load the boundaries\n",
    "boundaries = ee.FeatureCollection('projects/ndvi-inspire/assets/boundaries_uk')\n",
    "\n",
    "print(f'Loaded {boundaries.size().getInfo()} features')\n",
    "\n",
    "# Extract statistics\n",
    "veg_stats = composite.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=reducer,\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "pixel_stats = pixel_counts.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "# Export to your GCS bucket\n",
    "task1 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=veg_stats,\n",
    "    description='uk_veg_stats_2022',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_veg_stats_2022',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task2 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=pixel_stats,\n",
    "    description='uk_pixel_counts_2022',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_pixel_counts_2022',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task1.start()\n",
    "task2.start()\n",
    "\n",
    "print('Export tasks started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dad19d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://a-h-a-h/gee_exports/uk_veg_stats_2022.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "\\ [1 files][283.0 MiB/283.0 MiB]                                                \n",
      "Operation completed over 1 objects/283.0 MiB.                                    \n",
      "Copying gs://a-h-a-h/gee_exports/uk_pixel_counts_2022.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "\\ [1 files][272.1 MiB/272.1 MiB]                                                \n",
      "Operation completed over 1 objects/272.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Create the output directory for GEE exports if it doesn't exist\n",
    "output_dir = Path('data/raw_data/gee_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the vegetation statistics CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_veg_stats_2022.csv', str(output_dir)], check=True)\n",
    "# Download the pixel counts CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_pixel_counts_2022.csv', str(output_dir)], check=True)\n",
    "\n",
    "# Read the downloaded CSV files into pandas DataFrames\n",
    "veg_stats = pd.read_csv(output_dir / 'uk_veg_stats_2022.csv')\n",
    "pixel_counts = pd.read_csv(output_dir / 'uk_pixel_counts_2022.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb44e59",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fec3196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43914 features\n",
      "Export tasks started\n"
     ]
    }
   ],
   "source": [
    "# Cloud masking for Sentinel-2\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using SCL band, but keep original for pixel counting\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    \n",
    "    total_pixels = ee.Image.constant(1).rename('total_pixels')\n",
    "    valid_pixels = ee.Image.constant(1).updateMask(mask).rename('valid_pixels')\n",
    "    \n",
    "    return image.updateMask(mask).addBands([total_pixels, valid_pixels])\n",
    "\n",
    "\n",
    "def add_indices(image):\n",
    "    \"\"\"Calculate NDVI, EVI, and Fractional Vegetation Cover\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    nir = image.select('B8').divide(10000)\n",
    "    red = image.select('B4').divide(10000)\n",
    "    blue = image.select('B2').divide(10000)\n",
    "    \n",
    "    evi = nir.subtract(red).multiply(2.5).divide(\n",
    "        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n",
    "    ).rename('EVI')\n",
    "    \n",
    "    # Fractional Vegetation Cover\n",
    "    ndvi_soil = 0.2\n",
    "    ndvi_veg = 0.86\n",
    "    fvc = ndvi.subtract(ndvi_soil).divide(ndvi_veg - ndvi_soil).pow(2).clamp(0, 1).rename('FVC')\n",
    "    \n",
    "    return image.addBands([ndvi, evi, fvc])\n",
    "\n",
    "\n",
    "# Main processing\n",
    "start_date = '2021-04-01'\n",
    "end_date = '2021-10-31'\n",
    "\n",
    "s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "      .filterDate(start_date, end_date)\n",
    "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "      .map(mask_s2_clouds)\n",
    "      .map(add_indices))\n",
    "\n",
    "# Create composite\n",
    "composite = s2.select(['NDVI', 'EVI', 'FVC']).median()\n",
    "\n",
    "# Pixel counts - sum across collection\n",
    "pixel_counts = s2.select(['total_pixels', 'valid_pixels']).sum()\n",
    "\n",
    "# Build combined reducer for all stats\n",
    "reducer = (\n",
    "    ee.Reducer.mean()\n",
    "    .combine(ee.Reducer.median(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.stdDev(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.max(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.min(), sharedInputs=True)\n",
    "    .combine(ee.Reducer.count(), sharedInputs=True)\n",
    ")\n",
    "\n",
    "# Load the boundaries\n",
    "boundaries = ee.FeatureCollection('projects/ndvi-inspire/assets/boundaries_uk')\n",
    "\n",
    "print(f'Loaded {boundaries.size().getInfo()} features')\n",
    "\n",
    "# Extract statistics\n",
    "veg_stats = composite.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=reducer,\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "pixel_stats = pixel_counts.reduceRegions(\n",
    "    collection=boundaries,\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "# Export to your GCS bucket\n",
    "task1 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=veg_stats,\n",
    "    description='uk_veg_stats_2021',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_veg_stats_2021',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task2 = ee.batch.Export.table.toCloudStorage(\n",
    "    collection=pixel_stats,\n",
    "    description='uk_pixel_counts_2021',\n",
    "    bucket='a-h-a-h',\n",
    "    fileNamePrefix='gee_exports/uk_pixel_counts_2021',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task1.start()\n",
    "task2.start()\n",
    "\n",
    "print('Export tasks started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88766fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://a-h-a-h/gee_exports/uk_veg_stats_2021.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "/ [1 files][283.1 MiB/283.1 MiB]                                                \n",
      "Operation completed over 1 objects/283.1 MiB.                                    \n",
      "Copying gs://a-h-a-h/gee_exports/uk_pixel_counts_2021.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "/ [1 files][272.1 MiB/272.1 MiB]                                                \n",
      "Operation completed over 1 objects/272.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Create the output directory for GEE exports if it doesn't exist\n",
    "output_dir = Path('data/raw_data/gee_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the vegetation statistics CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_veg_stats_2021.csv', str(output_dir)], check=True)\n",
    "# Download the pixel counts CSV from Google Cloud Storage\n",
    "subprocess.run(['gsutil', 'cp', 'gs://a-h-a-h/gee_exports/uk_pixel_counts_2021.csv', str(output_dir)], check=True)\n",
    "\n",
    "# Read the downloaded CSV files into pandas DataFrames\n",
    "veg_stats = pd.read_csv(output_dir / 'uk_veg_stats_2021.csv')\n",
    "pixel_counts = pd.read_csv(output_dir / 'uk_pixel_counts_2021.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c521ade3",
   "metadata": {},
   "source": [
    "# Create Output Files from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a3dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved geoparquet to data/raw_data/gee_exports/Vegetation_Indices_2021.parquet\n",
      "Saved geoparquet to data/raw_data/gee_exports/Vegetation_Indices_2022.parquet\n",
      "Saved geoparquet to data/raw_data/gee_exports/Vegetation_Indices_2023.parquet\n",
      "Saved geoparquet to data/raw_data/gee_exports/Vegetation_Indices_2024.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_vegetation_data(year: int, boundaries_gdf, output_dir: Path = None):\n",
    "    \"\"\"\n",
    "    Process GEE vegetation exports for a given year and merge with boundaries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    year : int\n",
    "        Year to process (e.g., 2021, 2022, 2023, 2024)\n",
    "    boundaries_gdf : GeoDataFrame\n",
    "        UK boundaries with LSOA_DZ_SD column\n",
    "    output_dir : Path, optional\n",
    "        Directory containing GEE exports. Defaults to 'data/raw_data/gee_exports'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame\n",
    "        Boundaries merged with vegetation indices\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = Path('data/raw_data/gee_exports')\n",
    "    \n",
    "    # Read the CSV files for this year\n",
    "    pixel_counts = pd.read_csv(output_dir / f'uk_pixel_counts_{year}.csv')\n",
    "    veg_indices = pd.read_csv(output_dir / f'uk_veg_stats_{year}.csv')\n",
    "    \n",
    "    # Select relevant columns from vegetation indices\n",
    "    veg_cols = ['LSOA_DZ_SD']\n",
    "    for index in ['EVI', 'FVC', 'NDVI']:\n",
    "        for stat in ['count', 'max', 'mean', 'median', 'min', 'stdDev']:\n",
    "            veg_cols.append(f'{index}_{stat}')\n",
    "    \n",
    "    veg_indices = veg_indices[veg_cols]\n",
    "    \n",
    "    # Clean pixel counts\n",
    "    pixel_counts = pixel_counts.drop(columns=['system:index', '.geo'], errors='ignore')\n",
    "    \n",
    "    # Merge vegetation indices with pixel counts\n",
    "    veg_indices = veg_indices.merge(pixel_counts, on='LSOA_DZ_SD', how='left')\n",
    "    \n",
    "    # Merge with boundaries\n",
    "    result = boundaries_gdf.merge(\n",
    "        veg_indices,\n",
    "        on='LSOA_DZ_SD',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Save to parquet\n",
    "    out_path = output_dir / f'Vegetation_Indices_{year}.parquet'\n",
    "    result.to_parquet(out_path, index=False)\n",
    "    print(f\"Saved geoparquet to {out_path}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Process all years\n",
    "output_dir = Path('data/raw_data/gee_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "results = {}\n",
    "\n",
    "for year in years:\n",
    "    results[year] = process_vegetation_data(\n",
    "        year=year,\n",
    "        boundaries_gdf=boundaries_all_UK.copy(),  # Use copy to avoid modifying original\n",
    "        output_dir=output_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb6ee0",
   "metadata": {},
   "source": [
    "# 3 Year Average (2023-2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caea1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 43914 features\n",
      "Processing 2071217 images across 2023-2025 (Jun-Sep)\n",
      "Splitting into 88 batches of 500\n",
      "Started batch 1/88 (features 0-500)\n",
      "Started batch 2/88 (features 500-1000)\n",
      "Started batch 3/88 (features 1000-1500)\n",
      "Started batch 4/88 (features 1500-2000)\n",
      "Started batch 5/88 (features 2000-2500)\n",
      "Started batch 6/88 (features 2500-3000)\n",
      "Started batch 7/88 (features 3000-3500)\n",
      "Started batch 8/88 (features 3500-4000)\n",
      "Started batch 9/88 (features 4000-4500)\n",
      "Started batch 10/88 (features 4500-5000)\n",
      "Started batch 11/88 (features 5000-5500)\n",
      "Started batch 12/88 (features 5500-6000)\n",
      "Started batch 13/88 (features 6000-6500)\n",
      "Started batch 14/88 (features 6500-7000)\n",
      "Started batch 15/88 (features 7000-7500)\n",
      "Started batch 16/88 (features 7500-8000)\n",
      "Started batch 17/88 (features 8000-8500)\n",
      "Started batch 18/88 (features 8500-9000)\n",
      "Started batch 19/88 (features 9000-9500)\n",
      "Started batch 20/88 (features 9500-10000)\n",
      "Started batch 21/88 (features 10000-10500)\n",
      "Started batch 22/88 (features 10500-11000)\n",
      "Started batch 23/88 (features 11000-11500)\n",
      "Started batch 24/88 (features 11500-12000)\n",
      "Started batch 25/88 (features 12000-12500)\n",
      "Started batch 26/88 (features 12500-13000)\n",
      "Started batch 27/88 (features 13000-13500)\n",
      "Started batch 28/88 (features 13500-14000)\n",
      "Started batch 29/88 (features 14000-14500)\n",
      "Started batch 30/88 (features 14500-15000)\n",
      "Started batch 31/88 (features 15000-15500)\n",
      "Started batch 32/88 (features 15500-16000)\n",
      "Started batch 33/88 (features 16000-16500)\n",
      "Started batch 34/88 (features 16500-17000)\n",
      "Started batch 35/88 (features 17000-17500)\n",
      "Started batch 36/88 (features 17500-18000)\n",
      "Started batch 37/88 (features 18000-18500)\n",
      "Started batch 38/88 (features 18500-19000)\n",
      "Started batch 39/88 (features 19000-19500)\n",
      "Started batch 40/88 (features 19500-20000)\n",
      "Started batch 41/88 (features 20000-20500)\n",
      "Started batch 42/88 (features 20500-21000)\n",
      "Started batch 43/88 (features 21000-21500)\n",
      "Started batch 44/88 (features 21500-22000)\n",
      "Started batch 45/88 (features 22000-22500)\n",
      "Started batch 46/88 (features 22500-23000)\n",
      "Started batch 47/88 (features 23000-23500)\n",
      "Started batch 48/88 (features 23500-24000)\n",
      "Started batch 49/88 (features 24000-24500)\n",
      "Started batch 50/88 (features 24500-25000)\n",
      "Started batch 51/88 (features 25000-25500)\n",
      "Started batch 52/88 (features 25500-26000)\n",
      "Started batch 53/88 (features 26000-26500)\n",
      "Started batch 54/88 (features 26500-27000)\n",
      "Started batch 55/88 (features 27000-27500)\n",
      "Started batch 56/88 (features 27500-28000)\n",
      "Started batch 57/88 (features 28000-28500)\n",
      "Started batch 58/88 (features 28500-29000)\n",
      "Started batch 59/88 (features 29000-29500)\n",
      "Started batch 60/88 (features 29500-30000)\n",
      "Started batch 61/88 (features 30000-30500)\n",
      "Started batch 62/88 (features 30500-31000)\n",
      "Started batch 63/88 (features 31000-31500)\n",
      "Started batch 64/88 (features 31500-32000)\n",
      "Started batch 65/88 (features 32000-32500)\n",
      "Started batch 66/88 (features 32500-33000)\n",
      "Started batch 67/88 (features 33000-33500)\n",
      "Started batch 68/88 (features 33500-34000)\n",
      "Started batch 69/88 (features 34000-34500)\n",
      "Started batch 70/88 (features 34500-35000)\n",
      "Started batch 71/88 (features 35000-35500)\n",
      "Started batch 72/88 (features 35500-36000)\n",
      "Started batch 73/88 (features 36000-36500)\n",
      "Started batch 74/88 (features 36500-37000)\n",
      "Started batch 75/88 (features 37000-37500)\n",
      "Started batch 76/88 (features 37500-38000)\n",
      "Started batch 77/88 (features 38000-38500)\n",
      "Started batch 78/88 (features 38500-39000)\n",
      "Started batch 79/88 (features 39000-39500)\n",
      "Started batch 80/88 (features 39500-40000)\n",
      "Started batch 81/88 (features 40000-40500)\n",
      "Started batch 82/88 (features 40500-41000)\n",
      "Started batch 83/88 (features 41000-41500)\n",
      "Started batch 84/88 (features 41500-42000)\n",
      "Started batch 85/88 (features 42000-42500)\n",
      "Started batch 86/88 (features 42500-43000)\n",
      "Started batch 87/88 (features 43000-43500)\n",
      "Started batch 88/88 (features 43500-43914)\n",
      "\n",
      "Started 88 export tasks\n"
     ]
    }
   ],
   "source": [
    "# Cloud masking for Sentinel-2\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using SCL band\"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    mask = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "\n",
    "def add_ndvi(image):\n",
    "    \"\"\"Calculate NDVI\"\"\"\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "\n",
    "# 3-year window configuration\n",
    "years = [2023, 2024, 2025]\n",
    "start_month = 6  # June\n",
    "end_month = 9    # September\n",
    "\n",
    "# Build collection across 3 years, June-September only\n",
    "def get_summer_images(year):\n",
    "    \"\"\"Get June-September images for a given year\"\"\"\n",
    "    start_date = ee.Date.fromYMD(year, start_month, 1)\n",
    "    end_date = ee.Date.fromYMD(year, end_month + 1, 1)\n",
    "    \n",
    "    return (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40)))\n",
    "\n",
    "# Combine all years\n",
    "s2_collections = [get_summer_images(year) for year in years]\n",
    "s2 = ee.ImageCollection(s2_collections[0])\n",
    "for col in s2_collections[1:]:\n",
    "    s2 = s2.merge(col)\n",
    "\n",
    "# Apply masking and NDVI\n",
    "s2 = s2.map(mask_s2_clouds).map(add_ndvi)\n",
    "\n",
    "# Create composites: median, 75th, and 90th percentile\n",
    "ndvi_median = s2.select('NDVI').median().rename('NDVI_median')\n",
    "ndvi_p75 = s2.select('NDVI').reduce(ee.Reducer.percentile([75])).rename('NDVI_p75')\n",
    "ndvi_p90 = s2.select('NDVI').reduce(ee.Reducer.percentile([90])).rename('NDVI_p90')\n",
    "\n",
    "composite = ndvi_median.addBands(ndvi_p75).addBands(ndvi_p90)\n",
    "\n",
    "# Reducer for zonal statistics\n",
    "reducer = (\n",
    "    ee.Reducer.median()\n",
    ")\n",
    "\n",
    "# Load the boundaries\n",
    "boundaries = ee.FeatureCollection('projects/ndvi-inspire/assets/boundaries_uk')\n",
    "\n",
    "total_features = boundaries.size().getInfo()\n",
    "print(f'Loaded {total_features} features')\n",
    "print(f'Processing {s2.size().getInfo()} images across {years[0]}-{years[-1]} (Jun-Sep)')\n",
    "\n",
    "# Batching configuration\n",
    "batch_size = 500\n",
    "year_range = f'{years[0]}_{years[-1]}'\n",
    "\n",
    "boundaries_list = boundaries.toList(total_features)\n",
    "num_batches = (total_features + batch_size - 1) // batch_size\n",
    "print(f'Splitting into {num_batches} batches of {batch_size}')\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, total_features)\n",
    "    \n",
    "    batch = ee.FeatureCollection(boundaries_list.slice(start_idx, end_idx))\n",
    "    \n",
    "    ndvi_stats = composite.reduceRegions(\n",
    "        collection=batch,\n",
    "        reducer=reducer,\n",
    "        scale=10\n",
    "    )\n",
    "    \n",
    "    task = ee.batch.Export.table.toCloudStorage(\n",
    "        collection=ndvi_stats,\n",
    "        description=f'uk_ndvi_3yr_summer_{year_range}_batch{i:03d}',\n",
    "        bucket='a-h-a-h',\n",
    "        fileNamePrefix=f'gee_exports/ndvi_3yr_summer_{year_range}/ndvi_stats_batch{i:03d}',\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    \n",
    "    task.start()\n",
    "    tasks.append(task)\n",
    "    \n",
    "    print(f'Started batch {i+1}/{num_batches} (features {start_idx}-{end_idx})')\n",
    "\n",
    "print(f'\\nStarted {len(tasks)} export tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e878a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch000.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch001.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch002.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch003.csv...\n",
      "| [4 files][  4.6 MiB/  4.6 MiB]   84.6 KiB/s                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch004.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch005.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch006.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch007.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch008.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch009.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch010.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch011.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch012.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch013.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch014.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch015.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch016.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch017.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch018.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch019.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch020.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch021.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch022.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch023.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch024.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch025.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch026.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch027.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch028.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch029.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch030.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch031.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch032.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch033.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch034.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch035.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch036.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch037.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch038.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch039.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch040.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch041.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch042.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch043.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch044.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch045.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch046.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch047.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch048.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch049.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch050.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch051.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch052.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch053.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch054.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch055.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch056.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch057.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch058.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch059.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch060.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch061.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch062.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch063.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch064.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch065.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch066.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch067.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch068.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch069.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch070.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch071.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch072.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch073.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch074.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch075.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch076.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch077.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch078.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch079.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch080.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch081.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch082.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch083.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch084.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch085.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch086.csv...\n",
      "Copying gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/ndvi_stats_batch087.csv...\n",
      "/ [88 files][272.9 MiB/272.9 MiB]  218.9 KiB/s                                  \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 88 objects/272.9 MiB.                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 batch files\n",
      "Combined 43914 features to ndvi_stats_combined_2023_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "output_dir = Path('data/raw_data/gee_exports/ndvi_3yr_summer_2023_2025')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download all batch files from GCS\n",
    "subprocess.run([\n",
    "    'gsutil', 'cp', \n",
    "    'gs://a-h-a-h/gee_exports/ndvi_3yr_summer_2023_2025/*.csv', \n",
    "    str(output_dir)\n",
    "], check=True)\n",
    "\n",
    "# Combine all batch files\n",
    "csv_files = sorted(output_dir.glob('ndvi_stats_batch*.csv'))\n",
    "print(f'Found {len(csv_files)} batch files')\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in csv_files]\n",
    "combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save combined file\n",
    "combined.to_csv(output_dir / 'ndvi_stats_combined_2023_2025.csv', index=False)\n",
    "print(f'Combined {len(combined)} features to ndvi_stats_combined_2023_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe25b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/raw_data/gee_exports/ndvi_3yr_summer_2023_2025.parquet\n"
     ]
    }
   ],
   "source": [
    "combined_ndvi = pd.read_csv(output_dir / 'ndvi_stats_combined_2023_2025.csv')\n",
    "\n",
    "# keep LSOA_DZ_SD and any NDVI* columns, merge with boundaries, save\n",
    "ndvi_cols = [c for c in combined_ndvi.columns if c == 'LSOA_DZ_SD' or c.startswith('NDVI')]\n",
    "combined_ndvi_sub = combined_ndvi[ndvi_cols].copy()\n",
    "\n",
    "combined_gdf = boundaries_all_UK.merge(combined_ndvi_sub, on='LSOA_DZ_SD', how='left')\n",
    "\n",
    "out_path = Path('data/raw_data/gee_exports/ndvi_3yr_summer_2023_2025.parquet')\n",
    "combined_gdf.to_parquet(out_path, index=False)\n",
    "\n",
    "print(f\"Saved {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c85b3",
   "metadata": {},
   "source": [
    "# Create Outputs for Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb16bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load Vegetation Indices for each year\n",
    "veg_2021 = gpd.read_parquet(Path('data/raw_data/gee_exports/Vegetation_Indices_2021.parquet'))\n",
    "veg_2022 = gpd.read_parquet(Path('data/raw_data/gee_exports/Vegetation_Indices_2022.parquet'))\n",
    "veg_2023 = gpd.read_parquet(Path('data/raw_data/gee_exports/Vegetation_Indices_2023.parquet'))\n",
    "veg_2024 = gpd.read_parquet(Path('data/raw_data/gee_exports/Vegetation_Indices_2024.parquet'))\n",
    "veg_2025 = gpd.read_parquet(Path('data/raw_data/gee_exports/Vegetation_Indices_2025.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acfc484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Vegetation_Indices_2021.csv\n",
      "Saved Vegetation_Indices_2022.csv\n",
      "Saved Vegetation_Indices_2023.csv\n",
      "Saved Vegetation_Indices_2024.csv\n",
      "Saved Vegetation_Indices_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# Export vegetation data for each year as CSV files\n",
    "\n",
    "for year, veg_df in zip([2021, 2022, 2023, 2024, 2025], [veg_2021, veg_2022, veg_2023, veg_2024, veg_2025]):\n",
    "    # Drop geometry column for CSV export\n",
    "    csv_df = veg_df.drop(columns=['geometry'])\n",
    "    csv_path = f'Vegetation_Indices_{year}.csv'\n",
    "    csv_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
